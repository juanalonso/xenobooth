{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM7j0ZSc_9c"
      },
      "source": [
        "# XenoBooth\n",
        "Basado en el código de https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth, siguiendo el tutorial de https://medium.com/@pajunenpyry/easy-realistic-avatars-with-stable-diffusion-dreambooth-no-programming-step-by-step-seo-guide-no-711b70c91f69\n",
        "\n",
        "v1.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vH4BiAI5Bo-4"
      },
      "outputs": [],
      "source": [
        "#@title ## 1 Conectar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw"
      },
      "outputs": [],
      "source": [
        "#@title ## 2 Comprobar GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "#@title ## 3 Librerías y módulos\n",
        "\n",
        "%pip install -q torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "%pip install -q xformers==0.0.19 triton==2.0.0 -U\n",
        "\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio==3.48.0 natsort safetensors\n",
        "\n",
        "import gradio as gr\n",
        "import json\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from glob import glob\n",
        "from IPython.display import display, HTML\n",
        "from natsort import natsorted\n",
        "from torch import autocast\n",
        "\n",
        "def prettyprint(texto):\n",
        "  html = f\"<p style='font-size: large;'>{texto}</p>\"\n",
        "  display(HTML(html))\n",
        "  #print(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZbtVEw1BxKm"
      },
      "outputs": [],
      "source": [
        "#@title ## 4 El nombre de la cosa\n",
        "\n",
        "#@markdown Introduce el nombre -en inglés- de la clase (woman, man, child, boy, girl, person...)\n",
        "CLASS_NAME = \"woman\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Introduce el nombre de la instancia\n",
        "INSTANCE_NAME = \"brplz\" #@param {type:\"string\"}\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/\"\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "OUTPUT_DIR = f\"{BASE_DIR}xenobooth/{INSTANCE_NAME}/pesos\"\n",
        "INSTANCE_DATA_DIR = f\"{BASE_DIR}xenobooth/{INSTANCE_NAME}/selfies\"\n",
        "CLASS_DATA_DIR = f\"{BASE_DIR}xenobooth/data/{CLASS_NAME}\"\n",
        "GENERATION_DIR = f\"{BASE_DIR}xenobooth/{INSTANCE_NAME}/generadas\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(GENERATION_DIR, exist_ok=True)\n",
        "\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      \"photo of \" + INSTANCE_NAME + \" \" + CLASS_NAME,\n",
        "        \"class_prompt\":         \"photo of a \" + CLASS_NAME,\n",
        "        \"instance_data_dir\":    INSTANCE_DATA_DIR,\n",
        "        \"class_data_dir\":       CLASS_DATA_DIR\n",
        "    }\n",
        "]\n",
        "\n",
        "# print(f\"[*] Los pesos se almacenarán en la carpeta {OUTPUT_DIR}\")\n",
        "\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "    os.makedirs(c[\"class_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)\n",
        "\n",
        "CONCEPT = concepts_list[0][\"instance_prompt\"]\n",
        "\n",
        "prettyprint(f\"Copia los <b>ejemplos</b> en la carpeta <code>xenobooth/data/{CLASS_NAME}</code>\")\n",
        "prettyprint(f\"Copia tus <b>fotos</b> en la carpeta <code>xenobooth/{INSTANCE_NAME}/selfies</code>\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@title ## 5 Una vez copiadas, comprobamos que todo está OK\n",
        "\n",
        "NUM_IMAGES = 0\n",
        "for path in os.listdir(INSTANCE_DATA_DIR):\n",
        "    if os.path.isfile(os.path.join(INSTANCE_DATA_DIR, path)):\n",
        "        NUM_IMAGES += 1\n",
        "prettyprint(f'Has subido {NUM_IMAGES} imágenes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "#@title ## 6 Arranca el entrenamiento\n",
        "os.environ['CURL_CA_BUNDLE'] = ''\n",
        "\n",
        "num_class_images = NUM_IMAGES * 12\n",
        "max_train_steps = NUM_IMAGES * 80\n",
        "lr_warmup_steps = max_train_steps // 10\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "!python3 train_dreambooth.py \\\n",
        "  --num_class_images=$num_class_images \\\n",
        "  --max_train_steps=$max_train_steps \\\n",
        "  --lr_warmup_steps=$lr_warmup_steps \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --save_sample_prompt=\"$CONCEPT\" \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"fp16\" \\\n",
        "  --with_prior_preservation \\\n",
        "  --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --save_interval=10000 \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "end = time.time()\n",
        "print(f\"{end - start:.0f} segundos\")\n",
        "\n",
        "WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "prettyprint(f\"### WEIGHTS_DIR={WEIGHTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QB3iXe7iA0BR"
      },
      "outputs": [],
      "source": [
        "#@title ## 7 Primeros resultados\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('grid.png', dpi=72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGgQEVdOmMTQ"
      },
      "outputs": [],
      "source": [
        "#@title ## 8 Elegir modelo\n",
        "#@markdown  Será una ruta parecida a esta: /content/drive/MyDrive/xenobooth/INSTANCE_NAME/pesos/1200\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/xenobooth/brplz/pesos/1200\" #@param {type:\"string\"}\n",
        "\n",
        "if model_path == \"\":\n",
        "  try:\n",
        "    WEIGHTS_DIR\n",
        "  except NameError:\n",
        "    prettyprint(\"### ERROR: model_path no está definido\")\n",
        "  else:\n",
        "    if WEIGHTS_DIR is None or WEIGHTS_DIR == \"\":\n",
        "      prettyprint(\"### ERROR: model_path no está definido\")\n",
        "    else:\n",
        "      final_model_path = WEIGHTS_DIR\n",
        "      print(f\"model_path = {final_model_path}\")\n",
        "else:\n",
        "    final_model_path = model_path\n",
        "    print(f\"model_path = {final_model_path}\")\n",
        "if not os.path.isdir(final_model_path):\n",
        "    prettyprint(f\"## No encuentro la carpeta {final_model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW15FjffdTID"
      },
      "outputs": [],
      "source": [
        "#@title ## 9 Generar imágenes\n",
        "pipe = StableDiffusionPipeline.from_pretrained(final_model_path, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "def inference(prompt, negative_prompt, num_samples, random_seed, num_inference_steps=30, guidance_scale=9):\n",
        "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "        g_cuda.manual_seed(random_seed)\n",
        "        images = pipe(\n",
        "                prompt, height=int(512), width=int(512),\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=int(num_samples),\n",
        "                num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "        ahora = datetime.now().strftime('%H%M%S')\n",
        "        for index, image in enumerate(images):\n",
        "          image.save(f\"{GENERATION_DIR}/xeno_{ahora}_{index+1}.jpg\", quality=100, subsampling=0)\n",
        "        return images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", value=f\"a portrait of a {INSTANCE_NAME} {CLASS_NAME}, oil painting, by sorolla\")\n",
        "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"ugly, additional arms, additional legs, additional head, two heads, blurry, pixelated, extra hands, extra arms, collage, grainy, low, poor, monochrome\")\n",
        "            run = gr.Button(value=\"Generate\")\n",
        "            random_seed = gr.Slider(label=\"Seed\", value=2345678, maximum=9999999, step=1)\n",
        "            num_inference_steps = gr.Slider(label=\"Steps\", value=30)\n",
        "            with gr.Row():\n",
        "                num_samples = gr.Number(label=\"Number of Samples\", value=1)\n",
        "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=9)\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery().style(preview=True)\n",
        "\n",
        "    run.click(inference, inputs=[prompt, negative_prompt, num_samples, random_seed, num_inference_steps, guidance_scale], outputs=gallery)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}